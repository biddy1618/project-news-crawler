{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing crawler and site structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using `requests` library (non-asyncronous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "import urllib.parse as urlparse\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "URL_MAIN = 'https://www.inform.kz'\n",
    "URL_ARCHIVE = 'https://www.inform.kz/ru/archive'\n",
    "\n",
    "session = requests.Session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for the crawling links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for article links in the first page of archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links for articles (total 20 links) from main page:\n",
      "['https://www.inform.kz/ru/kitayskie-analitiki-predskazyvayut-obostrenie-geopoliticheskoy-napryazhennosti-v-2012g_a2430369', 'https://www.inform.kz/ru/samye-ozhidaemye-avtonovinki-2012-goda_a2430350', 'https://www.inform.kz/ru/v-kazahstane-sostavili-reyting-samyh-opasnyh-dorog-smi_a2430384', 'https://www.inform.kz/ru/v-ekibastuze-pri-pozhare-v-zhilom-dome-pogib-muzhchina-esche-odin-gospitalizirovan_a2430360', 'https://www.inform.kz/ru/na-filippinah-ot-pirotehniki-postradali-200-chelovek_a2430344']...\n"
     ]
    }
   ],
   "source": [
    "url_links = 'https://www.inform.kz/ru/archive?date=01.01.2012'\n",
    "response = session.get(url_links)\n",
    "soup = bs(response.content, 'html.parser')\n",
    "\n",
    "links = soup.find('div', class_='news-list__col').find_all('a')\n",
    "links = set([urlparse.urlparse(URL_MAIN + link['href'].strip()).geturl() for link in links])\n",
    "links = list(links)\n",
    "print(f'Links for articles (total {len(links)} links) from main page:\\n{links[:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for pagination links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagination links: ['https://www.inform.kz/ru/archive/2?date=01.01.2012']\n"
     ]
    }
   ],
   "source": [
    "soup = bs(response.content, 'html.parser')\n",
    "links = soup.find('p', class_='pagination').find_all('a')\n",
    "links = set([urlparse.urlparse(URL_MAIN + link['href'].strip()).geturl() for link in links])\n",
    "links = list(links)\n",
    "print(f'Pagination links: {links}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for articles from next page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links for articles (total 2 links) from next page:\n",
      "['https://www.inform.kz/ru/chislo-zhertv-ciklona-v-indii-vozroslo-do-42_a2430340', 'https://www.inform.kz/ru/ya-ot-vsego-serdca-zhelayu-chtoby-v-novom-godu-sbylis-vse-svetlye-mechty-i-nadezhdy-kazhdogo-kazahstanca-pozdravlenie-prezidenta-rk_a2430289']...\n"
     ]
    }
   ],
   "source": [
    "response = session.get(links[0])\n",
    "soup = bs(response.content, 'html.parser')\n",
    "\n",
    "links = soup.find('div', class_='news-list__col').find_all('a')\n",
    "links = set([urlparse.urlparse(URL_MAIN + link['href'].strip()).geturl() for link in links])\n",
    "links = list(links)\n",
    "print(f'Links for articles (total {len(links)} links) from next page:\\n{links[:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for crawling articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_articles(url):\n",
    "    response = session.get(url)\n",
    "\n",
    "    soup = bs(response.content, 'html.parser')\n",
    "\n",
    "    title = soup.find('div', class_='title_article_bl')\n",
    "    title = re.sub(r'\\s+', ' ', title.get_text().strip())\n",
    "\n",
    "    date = soup.find('div', class_='time_article_bl')\n",
    "    date = re.sub(r'\\s+', ' ', date.get_text().strip())\n",
    "    \n",
    "    links = []\n",
    "    links_frame = soup.find('div', class_='frame_news_article_adapt')\n",
    "    if links_frame:\n",
    "        links = links_frame.find_all('a')\n",
    "        links = set([urlparse.urlparse(URL_MAIN + link['href'].strip()).geturl() for link in links])\n",
    "        links = list(links)\n",
    "        links_frame.decompose()\n",
    "    \n",
    "    body = soup.find('div', class_='body_article_bl')\n",
    "    body = re.sub(r'\\s+', ' ', body.get_text().strip())\n",
    "    \n",
    "    tags = soup.find('div', class_='keywords_bl')\n",
    "    if tags:\n",
    "        tags = tags.find_all('a')\n",
    "        tags = [re.sub(r'\\s+', ' ', t.get_text().strip()) for t in tags]\n",
    "    else:\n",
    "        tags = []\n",
    "    \n",
    "    author = soup.find('div', class_='data_author_bl')\n",
    "    if author:\n",
    "        author = author.find('a')\n",
    "        author = re.sub(r'\\s+', ' ', author.get_text().strip())\n",
    "    else:\n",
    "        author = None\n",
    "    \n",
    "    print(f'Title: {title}')\n",
    "    print(f'Date: {date}')\n",
    "    print(f'Links (number of links - {len(links)}): {links[:3]}')\n",
    "    print(f'Tags: {tags}')\n",
    "    print(f'Author: {author}')\n",
    "    print(f'Body:\\n{body}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://www.inform.kz/ru/v-zhanaozene-prodolzhaetsya-rabota-po-blagoustroystvu-goroda_a2430452'\n",
    "url2 = 'https://www.inform.kz/ru/prezident-kazahstana-provel-peregovory-s-general-nym-sekretarem-oon_a3981340'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: В Жанаозене продолжается работа по благоустройству города\n",
      "Date: 2 Января 2012, 13:35\n",
      "Links (number of links - 0): []\n",
      "Tags: []\n",
      "Author: Дамир Байманов\n",
      "Body:\n",
      "АСТАНА. 2 января. КАЗИНФОРМ - В г. Жанаозен продолжаются мероприятия по вывозу бытового мусора и благоустройству города, сообщает pm.kz со ссылкой на пресс-службу акимата Мангыстауской областиПо информации пресс-службы, работа по очистке города завершена. В то же время продолжается уборка бытового мусора и благоустройство города. По данным на 1 января, в Жанаозене на уборочных работах с ГКП «Тазалык» задействовано 96 человек и 23 единицы специальной техники, вывезено 1154 тонн мусора.\n"
     ]
    }
   ],
   "source": [
    "check_articles(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Президент Казахстана провел переговоры с Генеральным секретарем ООН\n",
      "Date: 21 Сентября 2022, 05:06\n",
      "Links (number of links - 3): ['https://www.inform.kz/ru/glava-gosudarstva-podpisal-zakon-po-formirovaniyu-kadrovogo-sostava-eek_a3988798', 'https://www.inform.kz/ru/glava-gosudarstva-vstretil-v-stolichnom-aeroportu-emira-katara_a3989363', 'https://www.inform.kz/ru/prezident-prinyal-general-nogo-sekretarya-odkb_a3988814']\n",
      "Tags: ['ООН', 'Президент Казахстана']\n",
      "Author: Ринат Дусумов\n",
      "Body:\n",
      "НЬЮ-ЙОРК. КАЗИНФОРМ - Программа рабочего визита Касым-Жомарта Токаева в Нью-Йорк для участия в 77-й сессии Генеральной Ассамблеи ООН завершилась переговорами с Генеральным секретарем ООН Антониу Гутерришем, передает МИА «Казинформ» со ссылкой на пресс-службу Акорды. В ходе встречи, прошедшей в конструктивной и дружественной атмосфере, стороны обсудили состояние и перспективы укрепления многостороннего сотрудничества между Казахстаном и ООН. Особое внимание было уделено усилиям, направленным на выработку коллективных подходов к решению насущных вызовов современности. Президент высоко оценил лидерство Антониу Гутерриша на посту Генерального секретаря ООН и заявил о полной поддержке его инициативе о созыве «Саммита будущего» в 2024 году. Касым-Жомарт Токаев высказал надежду, что итоги этого важного мероприятия будут способствовать осуществлению Целям устойчивого развития. Стороны также рассмотрели ход реализации инициативы Главы нашего государства по созданию в городе Алматы Хаба ООН по Целям устойчивого развития для Центральной Азии и Афганистана. Генеральный секретарь ООН заявил о поддержке этой важной инициативы. Он также высоко оценил, реализуемые под руководством Президента Казахстана масштабные реформы в стране. В завершение Глава государства пригласил Антониу Гутерриша совершить визит в Казахстан.\n"
     ]
    }
   ],
   "source": [
    "check_articles(url2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing asyncronous HTTP using `aiohttp` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def _get_url(session, url):\n",
    "    '''\n",
    "    Function to perform GET request on the given url using the session object.\n",
    "\n",
    "    Args:\n",
    "        session (aiohttp.ClientSession): Session object.\n",
    "        url (str): URL to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: Response content in string format.\n",
    "    '''\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text()\n",
    "\n",
    "\n",
    "def retrieve_data(content):\n",
    "    '''\n",
    "    Get data from the response content of article.\n",
    "\n",
    "    Args:\n",
    "        content (str): String representation of the response content.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary object with scraped fields.\n",
    "    '''\n",
    "    soup = bs(content, 'html.parser')\n",
    "\n",
    "    title = soup.find('div', class_='title_article_bl')\n",
    "    title = re.sub(r'\\s+', ' ', title.get_text().strip())\n",
    "\n",
    "    date = soup.find('div', class_='time_article_bl')\n",
    "    date = re.sub(r'\\s+', ' ', date.get_text().strip())\n",
    "    \n",
    "    links = []\n",
    "    links_frame = soup.find('div', class_='frame_news_article_adapt')\n",
    "    if links_frame:\n",
    "        links = links_frame.find_all('a')\n",
    "        links = set([urlparse.urlparse(URL_MAIN + link['href'].strip()).geturl() for link in links])\n",
    "        links = list(links)\n",
    "        links_frame.decompose()\n",
    "    \n",
    "    body = soup.find('div', class_='body_article_bl')\n",
    "    body = re.sub(r'\\s+', ' ', body.get_text().strip())\n",
    "    \n",
    "    tags = soup.find('div', class_='keywords_bl')\n",
    "    if tags:\n",
    "        tags = tags.find_all('a')\n",
    "        tags = [re.sub(r'\\s+', ' ', t.get_text().strip()) for t in tags]\n",
    "    else:\n",
    "        tags = []\n",
    "    \n",
    "    author = soup.find('div', class_='data_author_bl')\n",
    "    if author:\n",
    "        author = author.find('a')\n",
    "        author = re.sub(r'\\s+', ' ', author.get_text().strip())\n",
    "    else:\n",
    "        author = None\n",
    "    \n",
    "    return {\n",
    "        'title': title,\n",
    "        'date': date,\n",
    "        'body': body,\n",
    "        'links': links,\n",
    "        'tags': tags,\n",
    "        'author': author\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of page links: 7.\n",
      "Number of artilces: 140.\n"
     ]
    }
   ],
   "source": [
    "async with aiohttp.ClientSession() as session:\n",
    "    # given the date, get the first page\n",
    "    url_for_date = 'https://www.inform.kz/ru/archive?date=01.04.2022'\n",
    "    response_main = await _get_url(session, url_for_date)\n",
    "\n",
    "    # get pagination links\n",
    "    soup = bs(response_main, 'html.parser')\n",
    "    links_pages = soup.find('p', class_='pagination').find_all('a')\n",
    "    links_pages = set([urlparse.urlparse(URL_MAIN + link['href'].strip()).geturl() for link in links_pages])\n",
    "    links_pages = list(links_pages)\n",
    "\n",
    "    response_pages = await asyncio.gather(*[\n",
    "        _get_url(session, link) for link in links_pages\n",
    "    ])\n",
    "\n",
    "    response_pages = [response_main] + response_pages\n",
    "    print(f'Number of page links: {len(response_pages)}.')\n",
    "\n",
    "    # get all articles\n",
    "    links_articles_all = []\n",
    "    for page in response_pages:\n",
    "        soup = bs(page, 'html.parser')\n",
    "\n",
    "        links_articles = soup.find('div', class_='news-list__col').find_all('a')\n",
    "        links_articles = set([urlparse.urlparse(URL_MAIN + link['href'].strip()).geturl() for link in links_articles])\n",
    "        links_articles_all.extend(list(links_articles))\n",
    "    print(f'Number of artilces: {len(links_articles_all)}.')\n",
    "\n",
    "    respose_articles = await asyncio.gather(*[\n",
    "        _get_url(session, link) for link in links_articles_all\n",
    "    ])\n",
    "\n",
    "    # get the articles data for single page\n",
    "    data = []\n",
    "    for r in respose_articles:\n",
    "        data.append(retrieve_data(r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('project-news-crawler')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9da460c27398f18e6779933e2bec45fa235f8f0ca483ea5c4cdb93b43914902b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
